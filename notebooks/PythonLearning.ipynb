{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Learning\n",
    "\n",
    "Using the Boost.Python library, I compiled my tic-tac-toe `Board` class as a library accessable to python 3.7. \n",
    "\n",
    "### To Do:\n",
    "- Added winner variable to TicTacToe class because it's messy to have to keep calling whoWon()\n",
    "- Develop DeepQAgent class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import Board\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe():\n",
    "    def __init__(self, player1, player2, p1_symbol=1, p2_symbol=-1, p1_exporation=0.8, p2_exporation=0.8):  \n",
    "        # define two players\n",
    "        self.p1_symbol = p1_symbol\n",
    "        self.p1_type = player1\n",
    "        self.p1_exporation = p1_exporation\n",
    "        self.p1_name = self.p1_type + str(self.p1_symbol)\n",
    "        player1 = globals()[self.p1_type]\n",
    "        self.player1 = player1(symbol=self.p1_symbol, name=self.p1_name, exploration=self.p1_exporation)\n",
    "        \n",
    "        self.p2_symbol = p2_symbol\n",
    "        self.p2_type = player2\n",
    "        self.p2_exporation = p2_exporation\n",
    "        self.p2_name = self.p2_type + str(self.p2_symbol)\n",
    "        player2 = globals()[self.p2_type]\n",
    "        self.player2 = player2(symbol=self.p2_symbol, name=self.p2_name, exploration=self.p2_exporation)\n",
    "        \n",
    "        self.turnPlayer = self.player1\n",
    "                \n",
    "        # turn couter\n",
    "        self.moveCounter = 1\n",
    "        \n",
    "        # initialize c++ game\n",
    "        self.game = Board.Board(int(self.p1_symbol), int(self.p2_symbol))\n",
    "        \n",
    "    def reinit(self):\n",
    "        self.moveCounter = 1\n",
    "        self.turnPlayer = self.player1\n",
    "        self.game = Board.Board(int(self.p1_symbol), int(self.p2_symbol))\n",
    "\n",
    "    def printMoveMap(self):\n",
    "        print(\"----------------\")\n",
    "        print(\"|  0 |  1 |  2 |\")\n",
    "        print(\"----------------\")\n",
    "        print(\"|  3 |  4 |  5 |\")\n",
    "        print(\"----------------\")\n",
    "        print(\"|  6 |  7 |  8 |\")\n",
    "        print(\"----------------\")\n",
    "        \n",
    "    def printGame(self):\n",
    "        gameBoard = self.game.getBoard()\n",
    "        print(gameBoard)     \n",
    "        \n",
    "    def play_pvp(self):\n",
    "        self.printMoveMap()\n",
    "        \n",
    "        while not self.game.isBoardFull() and self.game.whoWon() == 0:\n",
    "            print(\"Turn: \", self.moveCounter, \"Player: \", self.game.getTurnPlayer())\n",
    "            self.printGame()\n",
    "            \n",
    "            move = self.turnPlayer.getMove(self.game)\n",
    "            if self.game.addMove(move):\n",
    "                # successfully added move, so change turn player\n",
    "                if self.moveCounter % 2 == 1:\n",
    "                    self.turnPlayer = self.player2\n",
    "                else:\n",
    "                    self.turnPlayer = self.player1\n",
    "                    \n",
    "                self.moveCounter += 1\n",
    "        \n",
    "        if self.game.whoWon() != 0:\n",
    "            if self.player1.symbol == self.game.whoWon():\n",
    "                print(\"Player\", self.player1.name, \"(\", self.game.whoWon(), \")\", \"Won!\")\n",
    "            else:\n",
    "                print(\"Player\", self.player2.name, \"(\", self.game.whoWon(), \")\", \"Won!\")\n",
    "        elif self.game.isBoardFull():\n",
    "            print(\"Stalemate...\")\n",
    "        else:\n",
    "            print(\"Crazy Error: Uncaught stopping condition!\")\n",
    "        \n",
    "        print(\"Final Board:\")\n",
    "        self.printGame()\n",
    "        \n",
    "    def train(self, ngames, epochs=10):\n",
    "        # flush out results (recording and useage)\n",
    "        results = {'p1won': 0, 'p2won': 0, 'stalemate': 0, 'numturns': np.zeros((ngames,))}\n",
    "        \n",
    "        for game in tqdm(range(ngames)):\n",
    "            while not self.game.isBoardFull() and self.game.whoWon() == 0:\n",
    "                move = self.turnPlayer.getMove_train(self.game, epochs)\n",
    "                if self.game.addMove(move):\n",
    "                    if self.moveCounter % 2 == 1:\n",
    "                        self.turnPlayer = self.player2\n",
    "                    else:\n",
    "                        self.turnPlayer = self.player1\n",
    "\n",
    "                    self.moveCounter += 1\n",
    "            \n",
    "            results['numturns'][game] = self.moveCounter\n",
    "            self.reinit()\n",
    "            \n",
    "        self.player1.saveModel()\n",
    "        self.player2.saveModel()\n",
    "        \n",
    "        # print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human():\n",
    "    def __init__(self, symbol, exploration, name):\n",
    "        self.symbol = symbol\n",
    "        self.name = name\n",
    "        self.exploration = exploration\n",
    "        \n",
    "    def getMove_train(self, state, epochs):\n",
    "        return self.getMove(state)\n",
    "    \n",
    "    def getMove(self, state):\n",
    "        validMoves = state.getValidMoves()\n",
    "        keepTryingInputs = True\n",
    "        while keepTryingInputs:\n",
    "            move = int(input('Choose move: '))\n",
    "            keepTryingInputs = (move not in validMoves)\n",
    "        \n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rand():\n",
    "    def __init__(self, symbol, exploration, name):\n",
    "        self.symbol = symbol\n",
    "        self.exploration = exploration\n",
    "        self.name = name\n",
    "        \n",
    "    def getMove_train(self, state, epochs):\n",
    "        return self.getMove(state)\n",
    "    \n",
    "    def getMove(self, state):\n",
    "        randMove = int(np.random.choice(state.getValidMoves(), 1))\n",
    "        return randMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgent():\n",
    "    def __init__(self, symbol, exploration, name):\n",
    "        self.symbol = symbol\n",
    "        self.name = name\n",
    "        self.exploration = exploration\n",
    "        \n",
    "        self.prevBoard = np.zeros((3,3))\n",
    "        \n",
    "        self.model = self.loadModel()\n",
    "        \n",
    "    def loadModel(self):\n",
    "        modelPath = Path(self.name+'.h5')\n",
    "        if modelPath.is_file():\n",
    "            model = tf.keras.models.load_model(modelPath)\n",
    "            print('Model loaded:', self.name+'.h5')\n",
    "        else:\n",
    "            model = self.buildModel()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def buildModel(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=(3,3,1)))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(18, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(18, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(18, activation='linear'))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "                \n",
    "        return model\n",
    "    \n",
    "    def saveModel(self):\n",
    "        modelPath = Path(self.name+'.h5')\n",
    "        self.model.save(modelPath)\n",
    "        \n",
    "    def getMove_train(self, state, epochs=10):\n",
    "        winner = state.whoWon() # pl_symbol, p2_symbol, or 0\n",
    "        if state.isBoardFull() and winner == 0: # (0 could mean not done too)\n",
    "            winner = 'stalemate'\n",
    "        \n",
    "        prevValPredicted = self.model.predict(self.prevBoard.reshape(1,3,3,1))\n",
    "        reward = self.calcReward(winner)\n",
    "        \n",
    "        if winner == 0: # still playing\n",
    "            currValuePredicted = self.model.predict(state.getBoard().reshape(1,3,3,1))\n",
    "        else:\n",
    "            currValuePredicted = 0\n",
    "            \n",
    "        # estimate Q value\n",
    "        alpha = 0.5 # time discount\n",
    "        target = np.array(prevValPredicted + alpha*(reward + currValuePredicted - prevValPredicted))\n",
    "        \n",
    "        # train\n",
    "        self.model.fit(self.prevBoard.reshape(1,3,3,1), target, epochs=epochs, verbose=0)\n",
    "        \n",
    "        # increment state\n",
    "        self.prevBoard = state.getBoard()\n",
    "        \n",
    "        return self.getMove(state)\n",
    "    \n",
    "    def calcReward(self, winner):\n",
    "        reward = -1\n",
    "        if winner == self.symbol: # you/we won\n",
    "            reward = 1\n",
    "        elif winner == 0: # not done\n",
    "            reward = 0\n",
    "        elif winner is 'stalemate': # over, nobody won\n",
    "            reward = 0.5\n",
    "        else: # lost\n",
    "            reward = -1\n",
    "            \n",
    "        return reward\n",
    "     \n",
    "    def getMove(self, state):\n",
    "        validMoves = state.getValidMoves()\n",
    "        probBestMove = self.model.predict(state.getBoard().reshape(1,3,3,1))\n",
    "        \n",
    "        # I want the index [0:8] of the max, valid move in the original array\n",
    "        maxValidMove = probBestMove[0,validMoves].max()\n",
    "        move = np.where(probBestMove[0,:] == maxValidMove)\n",
    "        move = int(move[0][0])\n",
    "        \n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game = TicTacToe('DeepQAgent', 'DeepQAgent')\n",
    "game.train(1000, epochs=10)\n",
    "# game.play_pvp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TicTacToe('Human', 'DeepQAgent')\n",
    "game.play_pvp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
